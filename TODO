-   Research:
    *   Add cardinality to preprocessor [R]
    *   Report all (low cardinality, high cardinality) columns as correlated [C]
    *   Create synthetic data set; suggest as new benchmarks in case of non numerical data [C]
    *   Test outlier analysis on subset of intel dataset where elements aren't correlated [Z]
    *   Ensure that there is only one type per column -- later
    *   Further analysis of intel dataset [Z]
    *   Comparison to other algorithms (Census DB, TPCH) [Z]
    *   Mixture model thresholds [Z] [PAPER]
    *   Histogram-based correlations [C] [DONE, PAPER]
    *   Think about asymmetric features (like email addresses: we don't want to detect things that do not have '@' signs)
    *   Evaluate against other papers and real world annotated datasets [R] [PAPER]
    *   Identifying other outlier detection strategies / correlation detection strategies
    *   Closer look at references [R] [PAPER]
    *   Mixed discrete/continuous models, e.g. different distributions based on value of one field
-   Code:
    *   Make the plots more reproducible (integrate in the Makefile) [R]
    *   Look at correlations inside the expansion of a given field [LATER]
    *   Unit tests [Z, LATER]
    *   Adjust Gaussian to use data from statistical analysis [C, LATER]
    *   Train all models in one pass (instead of one per model) [C]
    *   New features: email validation [DONE], strings & floats to dates & times, ... [C/R]
    *   Artificial datasets for testing
