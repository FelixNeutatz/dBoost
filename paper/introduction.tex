\section{Introduction}
\label{sec:intro}

Sensor glitches, submission of incorrect input, and malicious activities are a few examples of events that can lead to the appearance of outliers in a dataset. If undetected, these values can skew statistics, support invalid conclusions, slow database operations, and cause otherwise avoidable expenses. On the other hand, careful analysis of these values can yield new insight about the data, prevent undesirable events, and generally improve the reliability of the data~\cite{Achour2014}.

Previous literature has generally defined an outlier as ``an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism'' \cite{Hawkins1980}, and has suggested a number of ways to detect and in some cases eliminate suspicious values. Previous approaches to outlier detection include modeling numerical data using Gaussian Mixture Models~\cite{Lu2005,Roberts1994,Roberts1999}, Histogram modeling~\cite{Gebski2007,Sheng2007}, and $k$-nearest neighbors~\cite{Ramaswamy2000}.

Little work, however, has focused on developing generic methods for user-guided outlier detection, providing sufficient flexibility to offer insight on widely diverse and heterogeneous data stored in typical relational database management systems. The relative inexpressivity of basic SQL types -- integers, strings, and doubles in particular -- might be to blame: strings, for example, can be used to store information as diverse as city names, email addresses, or phone numbers; the task rests on application logic to parse these values in and out of the databases. This paucity of semantic information leaves outlier detection algorithms with very little information to work with.

This paper presents an innovative approach to reporting and flagging outliers in highly heterogeneous datasets: our tools systematically expand semantically poor SQL types to derive richer information, and use this derived information as additional dimensions that can be used to detect outliers and provide detailed reports to the user. Expansion proceeds by applying a set of type-dependent rules, which function by mapping values of one type to a set of derived attributes. Integers, for example, can be expanded into dates and times (by considering them as Unix timestamps), or sets of booleans (by considering them as bit vectors). These rules are user-configurable and, when many rows in a database agree on a particular expanded attribute, can be used to express soft constraints on the data. For example, if most of the values in a string column have the same casing, then a soft constraint can be learned about the proper casing of values of that column. Expanded data can furthermore be analyzed to detect soft functional dependencies between derived attributes, enabling the detection of a broad class of data inconsistencies.

We designed the system to be both fast and memory efficient; it proceeds in three online passes over the data, keeping no more information than strictly necessary (in general, no more than a few dozen values per field in the database schema). The architecture is parallelizable, the analysis can be distributed over multiple computation nodes, and information can be kept from one run to the next so as to eliminate the first and possibly the second pass.

Our contributions are as follows:
\begin{enumerate}
\item We discuss the idea of tuple expansion, and a set of rules that proved useful in flagging outliers in heterogeneous datasets.
\item We describe a histogram-based approach in the context of detecting outliers in non-numerical, heterogeneous datasets.
\item We evaluate the performance of our system on several real-world datasets.
\end{enumerate}

The rest of this paper is structured as follows: In Section~\ref{sec:overview} we give an overview of our system, and in Section~\ref{sec:implementation} we discuss its technical aspects. We evaluate our tool on synthetic and real-world datasets in Section~\ref{sec:evaluation}, and we describe related work in Section~\ref{sec:related-work}. Finally, we conclude in Section~\ref{sec:conclusion}. % TODO \item We outline directions for future work in Section~\ref{sec:future-work}.
