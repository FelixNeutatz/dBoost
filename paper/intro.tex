% INTRODUCTION

%Detecting outliers is an important problem in detecting inconsistencies within a data set.
Sensor glitches, suspicious activity, and human input error can all result in the insertion of outlier rows in a database. If these rows go undetected, their presence can be detrimental to later database operations.

Formally, an outlier is defined as “an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism” \cite{Hawkins1980}.

While previous work has focused on detecting outliers before performing data analysis, no tools to our knowledge have been built to not only automatically detect, but also explain why outliers fall outside the expected data behavior.

In this work, we draw on some of the ideas from existing literature on statistical and probabilistic methods for outlier detection. We combine these into a framework that makes three passes over the data in order to analyze, model, and discover outliers in the data.

Our framework can be expanded naturally so that analysis and modeling can be done offline on a small sampling of the dataset. The data models can then be used to detect outliers in new data that is added to the database. Hence, outliers can be detected on-line without re-running any analysis on the rest of the data.

Our contributions are as follows:
\begin{enumerate}
\item We present a framework that detects outliers, using tuple expansion to extract relevant information from the data.
\item We apply machine learning techniques to model data behavior.
\item We evaluate the performance of our framework on several real-world datasets.
\end{enumerate}

We built a tool that utilizes our framework; it is publicly available under the GNU Public License~\cite{github}.

The rest of this paper is structured as follows:
We first provide an overview of our framework in Section~\ref{sec:overview}.
In Section~\ref{sec:implementation}, we delve into the details of how we built a software tool to implement our framework.
We evaluate our tool on several real-world problems in Section~\ref{sec:eval}.
We describe related work in Section~\ref{sec:related_work}, followed by our plans for future work in Section~\ref{sec:future} and conclusions from the project.
