% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012
% based on ACM SIGPROC-SP.TEX VERSION 2.7
% Modified by  Gerald Weber <gerald@cs.auckland.ac.nz>
% Removed the requirement to include *bbl file in here. (AhmetSacan, Sep2012)
% Fixed the equation on page 3 to prevent line overflow. (AhmetSacan, Sep2012)

\documentclass{vldb}
\usepackage{graphicx}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{url}


\begin{document}

% ****************** TITLE ****************************************

\title{Outlier Detection in Real Time}

% possible, but not really needed or used for PVLDB:
%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as\textit{Author's Guide to Preparing ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and BibTeX} at \texttt{www.acm.org/eaddress.htm}}}

% ****************** AUTHORS **************************************

% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} 

\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Rachael Harding\\
       %\affaddr{Massachusetts Institute of Technology}\\
       %\affaddr{}\\
       %\affaddr{}\\
       \email{rhardin@mit.edu}
% 2nd. author
\alignauthor
Zelda Mariet\\
       \email{mariet@mit.edu}
% 3rd. author
\alignauthor
Clement Pit--Claudel\\
       \email{cpitcla@mit.edu}
%\and  % use '\and' if you need 'another row' of author names
}
\date{10 December 2014}


\maketitle

\begin{abstract}
Databases are prone to input errors such as human error or faulty sensors.
Automatic detection of outliers in the input data would allow these errors to be detected and database administrators to be notified when input data does not fit the typical data set.
In this project, we build a tool to facilitate the automatic detection of outliers.
\end{abstract}




\section{Introduction}
Detecting outliers is an important problem in detecting inconsistencies within a data set.
Applications include detecting measurement errors from sensors, abnormal fluctuations in the stock market, credit card fraud, and human input error
Formally, an outlier is defined by Hawkins as “an observation which deviates so much from the other observations as to arouse suspicions that it was generated by a different mechanism.” \cite{Hawkins1980}.

In this work, we draw on some of the ideas from existing literature on outlier detection and statistical and probabilistic methods to detect data inconsistencies.
Our mechanism is able to learn what normal data looks like on small amounts of data. 
Based on static analysis, it can determine outliers from inputs added to databases in real time.
We build and evaluate a tool that automatically detects outliers based on dependencies between the data.

Our contributions are as follows:
\begin{enumerate}
\item A framework that detects outlying data on insert to a database
\item We apply machine learning techniques to model data behavior.
\end{enumerate}

\section{Related Work}

There has been substantial research in how to build models to detect outliers \cite{Aggarwal2013}, including how to detect outliers in high­dimensional data by searching the subspaces of the dat \cite{Zhang2004}\cite{Kriegel2009}.
However many of these algorithms are complex and can require substantial computation to determine whether a new data point lies outside the data.

Statistical methods have been used to detect functional dependencies between columns of relational databases for the purpose of informing the query optimizer of potential data dependencies \cite{Ilyas2004} 
These methods require only a small sample of the data to detect functional dependencies with high probability of correctness.
The relatively low computation required by these algorithms makes them more amenable to detecting data anomalies in real time.

\section{Framework}
We built a tool that analyzes datasets for outliers.
The tool is a three-pass process with the following stages:
\begin{enumerate}
%\item Tuple Expansion -- Tuples are expanded based on type.
\item Preprocessing -- Statistics are collected on data which can be used in future pipeline stages. The preprocessor also determines whether columns of expanded tuples are correlated.
\item Model Creation -- We use a variety of probabilistic models. 
\item Outlier Detection -- Using the models built on the existing dataset, we can detect outliers outside of specified parameters.
\end{enumerate}

\subsection{Tuple Expansion}
We expand tuples in order to harness isolated information about the data that may not be easy to see when looking at the data in its original form.
For example, the day of the week may be relevant information from a date, but unless the database stores this information in a separate column, the information is lost on most analyzers.
In order to capture this kind of information, we break down tuples into a series of sub-tuples based on the type of each column, along with the original value.
We determined these breakdowns based on our own intuition and the datasets we worked with.

\begin{itemize}
\item Strings
\begin{itemize}
\item Case: All upper or lower case, or title case.
\item Digits: Are there digits in the string?
\item Length: The length of the string in characters.
\end{itemize}
\item Dates
\begin{itemize}
\item Year, month, day
\item Hour, minute, seconds
\item Day of the week
\end{itemize}
\item Integers
\begin{itemize}
\item Bit position: What bits are activated?
\item Modulo: What is the value modulo some other value?
\end{itemize}
\item Floating Point
\begin{itemize}
\item Length: What is the significance of the number?
\end{itemize}
\end{itemize}

\subsection{Preprocessor}
After expanding each tuple by type, we feed the sub-tuples into a preprocessor which collect statistics on the dataset.
These statistics are used by the outlier models to improve performance.
We collect statistics by sub-tuple.
The statistics we collect include the average value of the column, its variance, and the maximum and minimum values. 

In addition to collecting statistics, we also run statistical analysis to determine whether there are correlations between different columns in the sub-tuples.
We use the Pearson R coefficient to do this correlation analysis, which we describe below.
If a sufficient correlation or inverse correlation is found, we pass the information about the tuples and subtuples that are correlated as hints to the outlier models.

\subsubsection{Pearson Product-Moment Correlation}
The Pearson product-moment correlation coefficient measures linear correlation between two vectors.
This simple, statistical method is commonly used to find correlation between multiple sets on values.
The formula to determine the coefficient, often represented as $R$, is the following.

$$
R = \frac{Covar(X,Y)}{Var(X)Var(Y)}
$$

The formula returns a value between -1 and 1, where a value close to 0 indicates no correlation, and the closer the value is to 1, the more correlated the columns are.

\subsection{Create Models}
\subsubsection{Gaussian Model}
\subsubsection{Gaussian Mixture Model}
\subsection{Outlier Detection}

\section{Evaluation}
\subsection{CSAIL Directory}
The CSAIL directory is an online directory of faculty, staff and students in the MIT Computer Science and Artificial Intelligence Laboratory \cite{CSAILDirectory}.
Each entry contains a person's name, phone number, office number, email address, and position.
Some data, such as a phone number, may be missing from the directory.

\subsection{Twitter}

\subsection{Intel Lab Data}
We evaluated our outlier detection models on some sensor data from the publicly available Intel Lab Data set \cite{IntelLabData}.
The Intel Lab Data contains data collected from 54 sensors spread throughout the Intel Berkeley Research Lab.ho
Each data entry is timestamped and contains information including humidity, temperature, light and voltage taken from a Micro2dot sensor and weatherboard.

This data set has known outliers from faulty sensor readings due to periods of critically low voltage.

\subsection{Presidential Campaign Finance}
\cite{PresCampaignData}

\section{Future Work}
\section{Conclusion}

% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{paper.bib}  % vldb_sample.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references

%\subsection{References}

%APPENDIX is optional.
% ****************** APPENDIX **************************************
% Example of an appendix; typically would start on a new page
%pagebreak

%\begin{appendix}

%\end{appendix}



\end{document}

