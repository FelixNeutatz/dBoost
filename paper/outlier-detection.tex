\subsection{Outlier Detection}
\label{sec:outlier-detection}

Models, once properly trained, are used for classification and detection of outliers -- either on incoming INSERT operations on a running system, or on existing rows (typically, the ones used during the model training phase). % LATER: Citation about databases sizes?

Given that databases can contain tables with several hundred columns, simply flagging a row as an outlier is insufficient: users cannot be expected to painstakingly analyze each outlying row. Instead, the tool automatically indicates which values in the row caused it to be flagged as an outlier.

\subsubsection{Simple Gaussian Modeling}
The simple Gaussian model measures how much each value differs from the mean computed in the preceding pass to flag outliers. Given a tolerance parameter $\theta$, a row is deemed an outlier if at least one of its attributes $a$ has a value $v_a$ such that
\begin{align}
  |v_a - \mu_a| \ge \theta \cdot \sigma_a
  \label{eqn:gaussian-outlier}
\end{align}
where $\mu_a$ and $\sigma_a$ are the model's parameters for column $a$, as described in Section~\ref{sec:gaus_model}.

In this model, detecting which values are responsible for the outlier flag is simply a matter of keeping track of which attributes satisfied Equation~\eqref{eqn:gaussian-outlier}. The simple Gaussian model does not take correlation hints into account.

\subsubsection{Mixture Modeling}
The Gaussian Mixture model uses the correlation hints provided by the statistical analysis phase to break down each row into small set of tuples of presumably correlated values.

The likelihood of each resulting tuple is then evaluated using the corresponding GMM. The model operates under the assumption that the data is accurately modeled by the chosen number of components for the GMM, and in particular that each non-outlying data point is well modeled by one of the Gaussians of the GMM. This makes it possible to detect outliers by flagging all tuples that are not accurately modeled by any of the components: if the probabilities of a tuple $t$ being generated by each of the Gaussian components are all smaller than the user-defined threshold parameter $\theta$ -- that is, if
\begin{align}
  \Pr(t, c | \pi_j, \mu_j, \Sigma_j) = \Pr(t | c, \pi_j, \mu_j, \Sigma_j) * \Pr(c | \pi_j)  \leq \theta
  \label{eqn:mixture-outlier}
\end{align}
 -- then the row is flagged as an outlier.\fxnote{I rephrased this a bit; $j$ should still be checked}

As in the Gaussian Model, providing the user with a list of attributes that caused the row to be flagged as an outlier is simply a matter of tracking correlations that failed test~\eqref{eqn:mixture-outlier}.

\subsubsection{Histogram Modeling}
The histogram-based modeling strategy proceeds in two phases to detect outliers.

First, after running through the learning phase, it decides for each histogram whether that histogram is ``peaked'' (contrasted, i.e. showing one strong mode) enough to be used to detect outliers. The aim of this phase is to discard histograms where most bins have a similar numbers of values. In practice, we use a simple statistical test to determine whether a histogram is sufficiently modal: we count the number of elements that fall into the most populated (``top'') bins, and discard the histogram if this count totals less than a user-specified proportion of values. Finding how many bins to include in the set of top bins is the most challenging part, and for this paper we explored two thresholding strategies (Figure~\ref{fig:peakiness}):

\begin{figure*}
  \centering
  \paddedgraphics[width=\linewidth]{../graphics/peakiness.pdf}
  \caption{Sample histograms, and corresponding decisions with distribution-dependent (\(D\)-independent) and distribution-independent (\(D\)-independent) thresholds. Each figure shows a sorted histogram, with the top bins hatched (in dotted green in the distribution-independent case, and in solid orange in the distribution-dependent case). The vertical arrows show the small value \(r=3\) in the distribution-dependent case. The weaknesses of the distribution-independent-model show in the third and fourth plots: in the third one the distribution-dependent strategy correctly rejects because of the small \(r\); in the fourth the distribution-independent strategy yields an incorrect threshold.}
  \label{fig:peakiness}
\end{figure*}

\begin{itemize}
\item \emph{Distribution-independent} -- Given a histogram with $N$ bins, we count the values in the top $1$ bins if $1 \leq N \leq 3$, $2$ bins if $4 \leq N \leq 5$, and $3$ bins for $3 \leq N \leq 16$ (histograms with $N > 16$ bins were previously discarded). This method is stable when the set of bins is static (week days, boolean values, \ldots), but it is sensitive to the addition of new bins.
\item \emph{Distribution-dependent} -- We sort the bins in decreasing order of bin size $b_i$, and find the index $i_{\max}$ such that the ratio $r = \sfrac{b_i}{b_{i+1}}$ is maximal (this calculation is safe, because the bin sizes are non-zero integers). We then count the values that falls in bins $[0 .. i_{\max}]$. In this case, we also reject histograms whose ``maximum jump'' is below a given threshold.
\end{itemize}

After identifying a relevant set of histograms (this operation only needs to run once, at the very beginning of the last pass), we proceed to the actual detection phase. We classify an expanded tuple $X$ as an outlier if any of its values (or set of values, as grouped according to the correlation hints previously obtained) $x_a$ verifies:
\begin{align}
h_a(x_a) \le \epsilon \sum_k h_a(k)
\label{eqn:hist-outlier}
\end{align}
where $h_a(x)$ designates the number of tuples with value $x$ for field $a$, and $\epsilon$ is a user-chosen sensitivity parameter.

In this model, identifying and reporting the outlying attributes is simply a matter of remembering which values $x_a$ failed test \eqref{eqn:hist-outlier}.
