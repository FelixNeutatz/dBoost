\subsection{Outlier Detection}
\label{sec:outlier-detection}

Models, once properly trained, are used for classification and detection of outliers -- either on incoming INSERT operations on a running system, or on existing rows (typically, the ones used during the model training phase). % LATER: Citation about databases sizes?

Given that databases can contain tables with several hundred columns, simply flagging a row as an outlier is insufficient: users cannot be expected to painstakingly analyze each outlying row. Instead, the tool automatically indicates which values in the row caused it to be flagged as an outlier.

\subsubsection{Simple Gaussian Modeling}
The simple Gaussian model measures how much each value differs from the mean computed in the preceding pass to flag outliers. Given a tolerance parameter $\epsilon$, a row is deemed an outlier if at least one of its attributes $a$ has a value $v_a$ such that
\begin{align}
  |v_a - \mu_a| \ge \epsilon \cdot \sigma_a
  \label{eqn:gaussian-outlier}
\end{align}
where $\mu_a$ and $\sigma_a$ are the model's parameters for column $a$, as described in Section~\ref{sec:gaus_model}.

In this model, detecting which values are responsible for the outlier flag is simply a matter of keeping track of which attributes satisfied Equation~\ref{eqn:gaussian-outlier}. The simple Gaussian model does not take correlation hints into account.

\subsubsection{Mixture Modeling}
The Gaussian Mixture model uses the correlation hints provided by the statistical analysis phase to break down each row into small set of tuples of presumably correlated values.

Each resulting tuple is then evaluated using the corresponding GMM; if the correlated values' $v_c$ probability is smaller than the user-defined threshold parameter $\theta$ -- that is, if
\begin{align}
  \Pr(v_c | \pi_c, \mu_c, \Sigma_c) \leq \theta
  \label{eqn:mixture-outlier}
\end{align}
 -- then the row is flagged as an outlier.

As in the Gaussian Model, providing the user with a list of attributes that caused the row to be flagged as an outlier is simply a matter of tracking correlations that failed test~\ref{eqn:mixture-outlier}.

\subsubsection{Histogram Modeling}
The histogram-based modeling strategy proceeds in two phases to detect outliers.

First, after running through the learning phase, it decides for each histogram whether that histogram is peaked enough that it may be used to detect outliers. The aim of this phase is to discard histograms where most bins have a similar numbers of values. In practice, we use a simple statistical test to determine whether a histogram is ``peaked'' (modal) enough: we count the number of elements that fall into the most populated bins, and discard the histogram if this count totals less than a user-specified proportion of values. Finding how many bins to include in the set of ``most populated'' bins is the most challenging part, and for this paper we explored two avenues:

\begin{itemize}
\item \emph{Distribution-independent} -- Given a histogram with $N$ bins, we count the values in the top $1$ bins if $1 \leq N \leq 3$, $2$ bins if $4 \leq N \leq 5$, and $3$ bins for $3 \leq N \leq 16$ (histograms with $N > 16$ bins were previously discarded). This method is stable when the set of bins is static (week days, boolean values, \ldots), but it is sensitive to the addition of new bins.
\item \emph{Distribution-dependent} -- We sort the bins in decreasing order of bin size $b_i$, and find the index $i_{\max}$ such that the ratio $\sfrac{b_i}{b_{i+1}$ is maximal (this calculation is safe, because the bin sizes are non-zero integers). We then count the values that falls in bins $[0 .. i_{\max}]$. In this case, we also reject histograms whose ``maximum jump'' is below a given threshold.
\end{itemize}

After identifying a relevant set of histograms (this operation only needs to run once, at the very beginning of the last pass), we proceed to the actual detection phase. We classify an expanded tuple $X$ as an outlier if any of its values (or set of values, as grouped according to the correlation hints previously obtained) $x_a$ verifies:
\begin{align}
h_a(x_a) \le \epsilon \sum_k h_a(k)
\label{eqn:hist-outlier}
\end{align}
where $h_a(x)$ designates the number of tuples with value $x$ for field $a$, and $\epsilon$ is a user-chosen sensitivity parameter.

In this model, identifying and reporting the outlying attributes is simply a matter of remembering which values $x_a$ failed test \ref{eqn:hist-outlier}.

\subsubsection{Meta-modeling through attribute-based partitioning}
The models presented above treat attributes and sets of correlated attributes as a whole. In some cases, however, it is possible to identify sub-populations by scrutinizing certain expanded attributes of the data; these sub-populations can then be studied separately, yielding more insight and better outlier classification performance.

The general approach, given a dataset and a pre-existing model, consists in extracting sets of attributes based on correlation hints provided by earlier stages of the pipeline, and splitting these set of attributes between a single key, and one or more sub-population attributes. One instance of the selected model is then built for each value of the key. 

This type of approach is useful when the distribution for an attribute or set of attributes is multi-modal. A high-level non-partitioned analysis will reveal values that fall in none of the classes; a partitioned approach, on the other hand, may more easily reveal discrepancies by suppressing interference between each class.

As an example, consider the case of an airline adjusting status levels for its frequent fliers, using the number of flights for each passenger as well as their status level. A non-partitioned analysis may not return any interesting information, but a partitioned analysis could single out passengers in lower status levels traveling significantly more than average, or instead passengers with higher status traveling rarely. This would work even if statuses are stored as textual data, with no indication of their relative rankings.

In addition to better classification performance, partitioning may lead to better runtime performance by diminishing the size of the dataset that each model covers. These benefits are most important when model construction performance does not scale linearly, and when data volumes are too large to be analyzed on a single machine. 

Finally attribute-based partitioning enabled analysis that was previously impossible. Assuming for example that a dataset with two columns has 4 classes identified by the value in the first column, each with 10 distinct expected values in the second column, a generic histogram-based analysis would discard the histogram for the pair of values as having too many-buckets (40). A partitioned analysis, on the other hand, would allow the construction of four histograms, each with 10 normal bins, and potentially a few outliers.

In our prototype implementation, we focused on partitioning applied to the discrete histogram case; the technique, however, generalizes to all the models presented above.

% As an example, consider a store that accepts multiple forms of payment. Instead of considering the data as a whole, one may segment it by payment medium, and model transactions that fall in each model separately. This may yield insight into the spending behaviours 
% A class instructor, for example, might provide students with two grades: one mid-term, letter-based grade, and one end-of-term numerical score. Modeling the data as a whole would 