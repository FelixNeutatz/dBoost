\subsection{Outlier Detection}
\label{sec:outlier-detection}

Models, once properly trained, are used for classification and detection of outliers -- either on incoming INSERT operations on a running system, or on existing rows (typically, the ones used during the model training phase). % LATER: Citation about databases sizes?

Given that databases can contain tables with tens or hundreds of columns, simply flagging a row as an outlier is insufficient: users cannot be expected to painstakingly analyze each outlying row. Instead, the tool automatically indicates which values in the row caused it to be flagged as an outlier.

\subsubsection{Simple Gaussian Modeling}
The simple Gaussian model measures how much each value differs from the mean computed in the preceding pass to flag outliers. Given a tolerance parameter $\theta$, a row is deemed an outlier if at least one of its attributes $a$ has a value $v_a$ such that
\begin{align}
  |v_a - \mu_a| \ge \theta \cdot \sigma_a
  \label{eqn:gaussian-outlier}
\end{align}
where $\mu_a$ and $\sigma_a$ are the model's parameters for column $a$, as described in Section~\ref{sec:gaus_model}.

In this model, detecting which values are responsible for the outlier flag is simply a matter of keeping track of which attributes satisfied Equation~\eqref{eqn:gaussian-outlier}. The simple Gaussian model does not take correlation hints into account, and thus simply report single-attribute outliers.

\subsubsection{Mixture Modeling}
The Gaussian Mixture model uses the correlation hints provided by the statistical analysis phase to break down each row into small set of tuples of presumably correlated values.

The likelihood of each resulting tuple is then evaluated using the corresponding GMM (Gaussian mixture model). The model operates under the assumption that the data is accurately modeled by the chosen number of components for the GMM, and in particular that each non-outlying data point is well modeled by one of the Gaussians of the GMM. This makes it possible to detect outliers by flagging all tuples that are not accurately modeled by any of the components: if the probabilities of a tuple $t$ being generated by each of the Gaussian components are all smaller than the user-defined threshold parameter $\theta$ -- that is, if
\begin{align}
  \Pr(t, c | \vec \pi, \vec \mu, \vec \Sigma) = \Pr(t | c, \vec \pi, \vec \mu, \vec \Sigma) \cdot \Pr(c | \vec \pi)  \leq \theta
  \label{eqn:mixture-outlier}
\end{align}
 -- then the row is flagged as an outlier.
 
As in the Gaussian Model, providing the user with a list of attributes that caused the row to be flagged as an outlier is simply a matter of tracking correlations that satisfied equation~\eqref{eqn:mixture-outlier}.

\subsubsection{Histogram Modeling}
The histogram-based modeling strategy proceeds in two phases to detect outliers.

First, after running through the learning phase, it decides for each histogram whether that histogram is ``peaked'' (i.e. showing or a few strong modes) enough to be used to detect outliers. The aim of this phase is to discard histograms where most bins have a similar number of values, and are thus not useful for outlier detection. In practice, we use a simple statistical test to determine whether a histogram is sufficiently modal: we count the number of elements that fall into the most populated (``top'') bins, and discard the histogram if this count totals less than a user-specified proportion of values. Finding how many bins to include in the set of top bins is the most challenging part, and for this paper we explored two thresholding strategies (Figure~\ref{fig:peakiness}):

\fxnote{Should we move this figure?}
\begin{figure*}
  \centering
  \paddedgraphics[width=\linewidth]{../graphics/peakiness.pdf}
  \caption{Sample histograms, and corresponding decisions with distribution-dependent (\(D\)-independent) and distribution-independent (\(D\)-independent) thresholds. Each figure shows a sorted histogram, with the top bins hatched (in dotted green in the distribution-independent case, and in solid orange in the distribution-dependent case). The vertical arrows show the small value \(r=3\) in the distribution-dependent case. The weaknesses of the distribution-independent-model show in the third and fourth plots: in the third one the distribution-dependent strategy correctly rejects because of the small \(r\); in the fourth the distribution-independent strategy yields an incorrect threshold.}
  \label{fig:peakiness}
\end{figure*}

\begin{itemize}
\item \emph{Distribution-independent} -- Given a histogram with $N$ bins, we count only the values in the top bin if $1 \leq N \leq 3$, in the top $2$ bins if $4 \leq N \leq 5$, and in the top $3$ bins for $3 \leq N \leq 16$ (histograms with $N > 16$ bins were previously discarded). This method is stable when the set of bins is static (week days, booleans, \ldots), but it is sensitive to the addition of removal of bins.
\item \emph{Distribution-dependent} -- We sort the bins in increasing order of bin size $b_i$, and find the index $i_{\max}$ such that the ratio $r = \sfrac{b_{i+1}}{b_{i}}$ is maximal (this calculation is safe, because the bin sizes are non-zero integers). If that ratio is under a user-defined threshold, we reject the histogram; otherwise, we consider bins $i_{\max} .. \texttt{end}$ to be ``top'' bins.
\end{itemize}

Figure~\ref{fig:peakiness} shows various types of histograms, and lists the conclusions that each of these two approaches yield.

After identifying a relevant set of histograms (this operation only needs to run once, at the very beginning of the last pass), we proceed to the actual detection phase. We classify an expanded tuple $X$ as an outlier if any of its values (or set of values, as grouped according to the correlation hints previously obtained) $x_a$ verifies:
\begin{align}
h_a(x_a) \le \epsilon \sum_k h_a(k)
\label{eqn:hist-outlier}
\end{align}
where $h_a(x)$ designates the number of tuples with value $x$ for field $a$, and $\epsilon$ is a user-chosen sensitivity parameter.

In this model, identifying and reporting the outlying attributes is simply a matter of remembering which values $x_a$ failed test \eqref{eqn:hist-outlier}.

\subsubsection{Partition-based modeling}
In the partition-based case, outlier are detected by the underlying models. To classify a given expanded tuple, each group of correlated attributes is divided between a one-attribute key and a group sub-population attributes. This group of attributes is then passed to the underlying model corresponding to the given value of the key, and the whole original tuple is reported as an outlier if any of its groups of sub-population attributes is marked as such by the underlying models.
